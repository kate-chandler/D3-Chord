

import pandas as pd
import numpy as np
import sys
import os
  

# Printing all values of array without truncation
np.set_printoptions(threshold=sys.maxsize)


data = pd.read_csv("2021-04-15FOM.csv",encoding='latin1',skiprows=1)

df = pd.DataFrame(data)


#reverse direction of slashes (backslashes mess up python)

df['FullName'] = df['FullName'].apply(lambda x: str(x).replace(os.sep, '/'))

#drop characters that tend to mess up python
df['FullName'] = df['FullName'].apply(lambda x: str(x).replace("'", ''))
df['FullName'] = df['FullName'].apply(lambda x: str(x).replace("?", ''))
df['FullName'] = df['FullName'].apply(lambda x: str(x).replace(")", ''))
df['FullName'] = df['FullName'].apply(lambda x: str(x).replace("(", ''))

#drop thumbs files and temp files

df['Drop'] = (df['FullName'].str.contains("thumbs.db",case=False) | df['FullName'].str.contains("~",case=False) |df['FullName'].str.contains("themedata",case=False) |df['FullName'].str.contains("colorschememapping",case=False))

df.drop(df[df['Drop'] == True ].index , inplace=True)

df = df.drop('Drop', 1)

#If your dataset contains multiple folders, and you want to visualize just one folder within that set, put the name of the relevant folder below

df['Drop2'] = (df['FullName'].str.contains("J:/Staff/Faculty of Management/Deans Office/Private",case=False))
df.drop(df[df['Drop2'] == False ].index , inplace=True)
df = df.drop('Drop2', 1)

#The visualization will feature the dups between folders on a specified hierarchical level. The hierarchical level is identified below (bigger numbers mean deeper hierarchical levels)

df['ShortNames'] = df['FullName'].str.split('/').str[5]


#deletes if a row on the dataset represents a file on the top level (ie. not within one of the folders).

df['ShortNames'].fillna(value="None",inplace=True)

df["isFile"] = (df['ShortNames'].apply(lambda x: (len(x) - str(x).rfind("."))<6))

df.drop(df[df['isFile'] == True ].index , inplace=True)
#
df = df.drop('isFile', 1)
#

#delete if it is an empty file

df["isEmpty"] = (df['FileHash'].apply(lambda x: x == 'E3B0C44298FC1C149AFBF4C8996FB92427AE41E4649B934CA495991B7852B855'))

df.drop(df[df['isEmpty'] == True ].index , inplace=True)
#
df = df.drop('isEmpty', 1)



#to make the file names more readable, you can remove the first part of the filepath


df['Doc'] = df['FullName'].apply(lambda x: str(x).replace('J:/Staff/Faculty of Management/Deans Office/Private','',1))

#Get rid of any trailing backslashes (otherwise, the subfolder-folder link will not match)
df['Doc'] = df['Doc'].apply(lambda x: str(x).rstrip('/'))

#Make the parent folder (essential for d3.stratify)

df['Folder'] = df.Doc.str.rsplit('/',1).str[0]


#if there are empty hash values (due to inadequacies of the dataset) you don't want them showing up as dups.  Instead, replace blanks with the index number (this ensures they are unique and won't be interpreted as dups)
df['FileHash'] = df['FileHash'].fillna(df.index.to_series())


#make a new dataset (df_merge) that represents the merged results of the original dataset (df)

df_merge = df.merge(df,on=['FileHash'])


#make a new column that indicates if the titles are equal (these are not true dups because the complete filepaths are the same)
df_merge["isEqual"] = (df_merge['FullName_x'] == df_merge['FullName_y'])

#delete rows with identical titles
df_merge.drop(df_merge[df_merge['isEqual'] == True ].index , inplace=True)

df_merge = df_merge.drop('isEqual', 1)

#turn the results of merge into a spreadsheet.  Once you put filters on, you can filter by shortnames to find the titles of dups shared across folders
#change the order so the shortnames are first

cols_to_move = ['ShortNames_x','ShortNames_y','FullName_x','FullName_y']
df_merge = df_merge[ cols_to_move + [ col for col in df_merge.columns if col not in cols_to_move ] ]
df_merge.to_csv("NamesOfDuplicates.csv")

#get a count of dups for general information

dfDupCount = df_merge.duplicated(subset=['FileHash'],keep=False).sum()

print('Number of Duplicates in these folders: ', dfDupCount)

#make a matrix representing the frequency of one shortname appearing in the same row as another shortname
results = pd.crosstab(df_merge.ShortNames_x, df_merge.ShortNames_y)

#If you only want to see the dups that are spread into different folders (rather than internal to one folder), delete the values representing the internal folders

# np.fill_diagonal(results.values, 0)

#print the folders names (these will be copy-pasted into D3)
print(repr(results.columns))

#print the matrix (these will be copy-pasted into D3)
print(repr(results.values))
